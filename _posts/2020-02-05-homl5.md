---
layout: post
title: 5. Support Vector Machines(SVM)
category: Hands on Machine Learning
tag: Machine-Learning
---





**서포트 벡터 머신** (Support Vector Machine, SVM)은 매우 강력하고 선형이나 비선형, 분류, 회귀, 이상치 탐색 등 여러 곳에 사용할 수 있는 다목적 머신러닝 모델이다. 특히 복잡한 분류 문제에 잘 들어맞으며 작거나 중간 크기의 데이터셋에 적합하다.  



## 1) 선형 SVM 분류

아래의 그림을 보자. 왼쪽 3개의 직선은 선형 분류 모델에 의해 분류된 결정 경계이다. 그 중 점선은 데이터셋을 적절하게 분류하지 못하고 있고, 나머지 2개의 직선은 분류는 제대로 하고 있으나 결정 경계가 샘플과 너무 가까워 새로운 샘플에는 잘 작동하지 못할 확률이 있다. 반면, 오른쪽 직선은 SVM에 의해 형성된 결정 경계다. 이 직선은 두 개의 클래스를 나누고 있을 뿐만 아니라 제일 가까운 훈련 샘플로부터 가능한 한 멀리 떨어져있기도 하다. SVM된 분류기를 이런 특징에 따라 SVM 분류기를 **라지 마진 분류** (Large Margin Classification)라고도 한다.



결정 경계가 도로 경계에 위치한 샘플에 의해 전적으로 결정되기 때문에 도로 바깥쪽에는 훈련 샘플을 더 추가하더라도 결정 경계는 변하지 않는다. 이렇게 도로 경계에 있는 샘플을 **서포트 벡터** (Support Vector)라고 한다. 서포트 벡터는 특성의 스케일에 굉장히 민감하므로 특성 스케일링을 해주면 결정 경계가 훨씬 좋아진다.

**소프트 마진 분류** (Soft Margin Classification) : 위 그림처럼 모든 샘플을 도로 바깥쪽으로 분류하는 것을 **하드 마진 분류** (Hard Margin Classification) 라고 한다. 하드 마진 분류는 데이터를 선형적으로 구분할 수 있을 때에만 제대로 작동하며, 이상치에 민감하다는 문제점이 있다. 이런 문제를 피하기 위해서 유연한 모델이 필요한데, 이를 **소프트 마진 분류** (Soft Margin Classification)라고 한다. 소프트 마진 분류에서는 샘플이 잘못 분류되는 마진 오류와 도로의 폭을 가능한 한 넓게 유지하는 것 사이의 균형을 잡는 것이 중요해진다.



사이킷런의 SVM 모델에서는 하이퍼파라미터 C를 사용하여 이 균형을 조절할 수 있다. C값을 줄이면 도로의 폭이 넓어지지만 마진 오류도 커진다. 반대로 C값이 커질수록 도로의 폭이 줄어들지만 마진 오류 또한 줄어들게 된다. 사이킷런에서는 다음과 같은 코드로 SVM 모델을 학습시킬 수 있다.

```python
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC

svm_clf = Pipeline([
	("scaler", StandardScaler()),
	("linear_svc", LinearSVC(C=1, loss="hinge"))
])
# 힌지 손실 함수는 후에 등장한다.
# SVM 분류기는 로지스틱 회귀 분류기와는 다르게 확률을 제공하지는 않는다.
svm_clf.fit(X, y)
```

<br/>

## 2) 비선형 SVM 분류

비선형 데이터셋을 다루는 한 가지 방법은 다항 특성과 같은 특성을 더 추가하는 것이다. 사이킷런으로 다항 특성을 추가한 SVM을 다루는 코드는 아래와 같다.

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures

polynomial_svm_clf = Pipeline([
	("poly_features", PolynomialFeatures(degree=3)),
	("scaler", StandardScaler()),
	("svm_clf", LinearSVC(C=10, loss="hinge"))
])
polynomial_svm_clf.fit(X, y)
```

**다항 커널** : 비선형 SVM 모델에서 낮은 차수의 다항식으로는 복잡한 데이터셋을 잘 표현하지 못하고, 높은 차수의 다항식은 특성이 늘어나 모델을 느리게 한다는 문제점을 가지고 있다. SVM은 **커널 트릭** (kernel trick) 이라는 기법을 사용해 난관을 헤쳐나갈 수 있다. 이 기법은 SVC 파이썬 클래스에 구현되어 있고, 사용하는 방법은 다음과 같다.

```python
from sklearn.svm import SVC
poly_kernel_svm_clf = Pipeline([
	("scaler", StandardScaler())
	("svm_clf", SVC(kernel="poly", degree=3, coef0=1, C=5))
])
poly_kernel_svm_clf.fit(X,y)
```

위 코드에서는 3차 다항식이 되도록 사용했다. 모델이 과대적합이라면 다항식의 차수를 줄여야 하며, 과소적합이라면 다항식의 차수를 늘려야 한다. 하이퍼파라미터 coef0는 모델이 높은 차수와 낮은 차수에 얼마나 영향을 받을지 조절한다.

**유사도 특성 추가** : 유사도 특성 추가는 비선형 특성을 다루는 또 다른 기법이다. 샘플이 특정 **랜드마크** (landmark)와 얼마나 닮았는지 측정하는 **유사도 함수** (similarity function) 로 계산한 특성을 추가한다. 유사도 함수는 다음과 같다.<br/>
$$
\begin{gather}
\phi_\gamma (\mathbf{x}, l) = \exp(-\gamma\vert\vert\mathbf{x}-l\vert\vert^2)
\end{gather}
$$

- $\gamma$ : **가우시안 방사 기저 함수** (RBF, Radical Basis Function)
- $l$ : 샘플과 랜드마크 사이의 거리

예를 들어, 1차원 데이터셋에 2개의 랜드마크 $x_1 = -2, x_1=1$ 를 추가하고, $\gamma = 0.3$ 이라고 하자. $x_1 = -1$ 샘플은 첫 번째 랜드마크에서는 1만큼, 두 번째 랜드마크에서는 2만큼 떨어져 있다. 그러므로 새로 만든 특성은 각각 $x_2 = \exp(-0.3 * 1^2) = 0.74$ 와 $x_3 = \exp(-0.3 * 2^2) = 0.30$ 이다. $x_2, x_3$ 를 기준으로 샘플을 맵핑하면 이제 선형으로 구분이 가능하게 된다.

<br/>

**가우시안 RBF 커널** (Gaussian RBF Kernel) : 다항 특성 방식과 마찬가지로 유사도 특성 방식도 머신러닝 알고리즘에 유용하게 사용된다. 데이터의 수가 많은 경우 추가 특성을 모두 계산하려면 연산 비용이 많이 드는데, 이 문제를 **커널 트릭** 이 해결해준다. 커널 트릭을 사용하면 유사도 특성을 많이 추가하는 것과 같은 비슷한 결과를 실제로 특성을 추가하지 않고 얻을 수 있다. 아래와 같은 코드로 SVC 모델에 가우시안 RBF 커널을 적용할 수 있다.

```python
rbf_kernel_svm_clf = Pipeline([
    ("scaler", StandardScaler()),
    ("svm_clf", SVC(kernel="rbf", gamma=5, C=0.001))
])
```

이 모델을 기준으로 하이퍼파라미터 $\gamma$ 와 C를 변경시키며 그린 결정 경계를 나타내면 아래와 같다. 여기서는 $\gamma$ 이 규제의 역할을 한다. $\gamma$ 를 증가시키면 종 모양 그래프가 좁아지면서 각 샘플이 영향을 주는 범위가 좁아진다. 결정 경계가 좀 더 불규칙해지고 각 샘플을 따라 구불구불하게 휘어진다. 반대로 작은 $\gamma$ 값은 넓은 종 모양 그래프를 만들고, 결정 경계가 더 부드러워진다. 모델이 과대적합인 경우 $\gamma$ 를 감소시켜야 하며, 과소적합인 경우에는 $\gamma$ 를 높여주어야 한다.

<br/>

가우시안 RBF 커널 대신에 다른 커널을 사용할 수도 있지만 잘 사용되지 않는다. Ex) 문자열 커널(문자열 서브시퀀스 커널, 레벤슈타인 거리 기반의 커널)[^1]

 **계산복잡도** : LinearSVC는 커널 트릭을 지원하지는 않지만, 시간 복잡도가 훈련 샘플과 특성 수에 거의 선형적으로 늘어난다. (대략 $O(m*n)$ 정도의 시간복잡도를 가진다.) 또한, 정밀도를 높이면 시간복잡도가 늘어나며 이는 허용오차 하이퍼파라미터 $\epsilon$ 으로 조절한다. 대부분의 분류 문제는 허용오차를 기본값으로 두면 잘 작동하게 된다.

SVC의 시간복잡도는 보통 $O(m^2*n)$ 와 $O(m^3*n)$ 사이에 있다. 이것은 샘플 수(m)가 늘어날수록 모델이 엄청나게 느려진다는 것을 의미한다. 반대로 특성의 개수(n)에는 크게 영향 받지 않고 잘 늘어나며, 특히 희소 특성의 경우에 더욱 잘 확장된다. 

<br/>

## 3) SVM 회귀

SVM 회귀 모델은 위에서 언급되었던 선형, 혹은 비선형 분류와는 다르게 작동한다. 분류 모델이 일정한 모델 안에서 도로 폭이 최대가 되도록 하는 것이었다면, SVM 회귀는 제한된 마진 오류 안에서 도로 안에 가능한 한 많은 샘플이 들어가도록 학습한다. 도로의 폭은 하이퍼파라미터 $\epsilon$ 으로 조절한다. 이렇게 되면 마진 안쪽에 아무리 많은 훈련 샘플이 추가되더라도 모델의 예측에는 영향이 없기 때문에, 이 모델을 $\epsilon$ 에 민감하지 않다 ( $\epsilon$ - insensitive) 고 말합니다.

```python
from sklearn.svm import LinearSVR, SVR
svm_reg = LinearSVR(epsilon=1.5)
svm_reg.fit(X, y)

svm_poly_reg = SVR(kernel="poly", degree=2, C=100, epsilon=0.1)
svm_poly_reg.fit(X, y)
```

위의 코드를 사용하면 사이킷런의 LinearSVR로 선형 회귀를, SVR로 비선형 회귀를 적용할 수 있다. LinearSVR, SVR은 각각 LinearSVC, SVC의 회귀 버전이다. 특성도 동일하여, LinearSVR은 필요한 시간이 훈련 세트의 크기에 비례해서 선형적으로 늘어나지만, SVR은 훈련 세트가 커지면 시간은 훨씬 더 많이 증가하게 된다. 

<br/>

## 4) SVM 이론

**결정 함수와 예측** (Decision Function and Predictions) : 선형 SVM은 아래와 같은 식을 생성하여 새로운 샘플 $\mathbf{x}$ 의 클래스를 예측한다.
$$
\begin{gather}
\mathbf{w}^T \mathbf{x} + b = w_1x_1 + w_2x_2 + ... + w_nx_n + b
\end{gather}
$$

- $\mathbf{w}$ : 특성 가중 벡터 (feature weights vector)
- $b$ : 편향 (bias)

$$
\begin{gather}
\hat{y} = \begin{cases} 0 \qquad \text{when} \quad \mathbf{w}^T \cdot \mathbf{x} + b < 0  \\ 1 \qquad \text{when} \quad\mathbf{w}^T \cdot \mathbf{x} + b >0\end{cases}
\end{gather}
$$

해당 함수의 값이 0보다 클 경우 예측 클래스 $\hat{y}$ 는 양성 클래스가 되고 그렇지 않으면 음성 클래스로 분류된다. 



**목적 함수** : 위에서 나타난 결정 함수의 기울기는 가중치 벡터 $||\mathbf{w}||$ 의 노름과 같다. 아래의 그림에서 가중치 벡터 $\mathbf{w}$ 가 작을수록 마진이 커지는 것을 볼 수 있다. 마진을 크게 하기 위해 $||\mathbf{w}||$ 를 최소화 한다고 하자. 이 과정에서 마진 오류를 하나도 만들지 않으려면(하드 마진), 결정 함수가 모든 양성 훈련 샘플에서는 1보다 커야 하고 음성 훈련 샘플에서는 -1보다 작아야 한다. 즉 음성 샘플 $y^{(i)} = 0$ 일 때 $t^{(i)} = -1$ 로, 양성 샘플 $y^{(i)} = 1$ 일 때 $t^{(i)} = 1$ 로 정의하면, 앞서 말한 모든 제약 조건은 샘플에서 아래와 같은 식으로 표현할 수 있다.
$$
\begin{gather}
t^{(i)}(\mathbf{w}^T \cdot \mathbf{x}^{(i)} + b) \geq 1
\end{gather}
$$
그러므로 하드 마진 선형 SVM 분류기의 목적 함수를 **제약이 있는 최적화** (Constrained optimization) 문제로 표현할 수 있다.[^2]
$$
\begin{gather}
\text{minimize} \quad \frac{1}{2}\mathbf{w}^T \cdot \mathbf{w} \\ \text{subject to} \quad t^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b) \geq 1 \quad \text{for i}= 1, 2, ..., m
\end{gather}
$$
하드 마진이 아닌 소프트 마진 분류기의 목적 함수를 구성하려면 각 샘플에 대해 **슬랙 변수** (Slack Variable, $\zeta^{(i)} \geq 0$ )를 추가해주어야 한다. $\zeta^{(i)}$ 는 $i$ 번째 샘플이 얼마나 마진을 위반할 지 정한다. 

**콰드라틱 프로그래밍** : 

**쌍대 문제** :

**커널 SVM** :

**온라인 SVM** : 

<br/>



​                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          

[^1]: 어떤 커널을 먼저 사용해야 할 까? 대개 선형 커널을 1순위로 사용하며, 훈련 세트가 너무 크지 않다면 가우시안 RBF 커널을 시도해볼 수 있다.
[^2]: $||\mathbf{w}||$ 를 최소화하는 대신 $\frac{1}{2}||\mathbf{w}||^2$ 인 $\frac{1}{2} \mathbf{w}^T \cdot \mathbf{w}$ 를 최소화 한다. (결과는 같지만 후자가 미분하기가 더 깔끔하다.)