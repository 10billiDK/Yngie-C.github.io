---
layout: post
title: 1. 한눈에 보는 머신러닝
category: Machine Learning
tag: Machine-Learning
---

 

## 1) 머신러닝이란?

머신러닝에 대한 정의

> "명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다." - Arthur Samuel, 1959
>
> "어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다." - Tom Michell, 1997

<br/>

## 2) 왜 머신러닝을 사용하는가?

전통적인 방법(사람이 모델을 만들어내는)으로는 __복잡한 문제__ (이를테면, 스팸 메일을 분류해주는 필터기)를 풀기 어렵다. 반면 __머신러닝 기법__ (어떤 메일이 스팸 메일인지 자동으로 기계가 학습)을 사용하면 __프로그램이 짧아져__ 유지보수하기 쉬우며 대부분 __정확도__ 가 더 높다.

<br/>

## 3) 머신러닝 시스템의 종류

- 지도학습과 비지도 학습

  - **지도 학습** (Supervised Learning) : 알고리즘에 주입하는 훈련 데이터에 __레이블__ (label)이라는 원하는 답이 포함된다. ( _분류, 회귀 등_ )
    - k - 최근접 이웃(k-Nearest Neighbors, kNN)
    - 선형 회귀(Linear Regression)
    - 로지스틱 회귀(Logistic Regression)
    - 서포트 벡터 머신(Support Vector Machine, SVM)
    - 결정 트리(Decision Tree)와 랜덤 포레스트(Random Forest)
    - 신경망(Neural Networks)

  - **비지도 학습** (Unsupervised Learning) : 시스템이 아무런 도움(레이블 사전 주입)없이 학습한다.
    - 군집(Clustering) : k-평균(k-Means), 계층 군집 분석(Hierarchical Cluster Analysis, HCA), 기댓값 최대화(Expectation Maximization)
    - 시각화(Visualization)와 차원축소(Dimensionality reduction) : 주성분 분석(Principal Component Analysis, PCA), 커널 PCA(kernal PCA), 지역적 선형 임베딩(Locally-Linear Embedding, LLE), t-SNE(t-distributed Stochastic Neighbor Embedding)
    - 연관 규칙 학습(Association rule learning) : 아프리오리(Apriori), 이클렛(Eclat)

  - **준지도 학습** (Semisupervised Learning)과 **강화 학습** (Reinforcement Learning)
    - 준지도 학습 : 어떤 알고리즘은 레이블이 일부만 있더라도 적용할 수 있다. 이를 준지도 학습이라고 한다. 대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있다. 예를 들어, **심층 신뢰 신경망** (Deep Belief Network, DBN)은 여러 겹으로 쌓은 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM)이라 불리는 비지도 학습에 기초한다.
    - 강화 학습 : 강화학습에서는 학습하는 시스템을 **에이전트** 라고 부르며 환경을 관찰해서 행동을 실행하고 그 결과로 보상(혹은 벌점)을 받는다. 시간이 지나면서 가장 큰 보상을 얻기 위해서 정책이라고 부르는 최상의 전략을 스스로 학습한다. 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할 지 정의한다.

- 배치 학습과 온라인 학습
  - 배치 학습 : 데이터 셋을 미리 준비한 뒤 모든 데이터를 사용하여 학습. 방법이 간단하지만, 시스템이 빠르게 변화해야 하는 상황 혹은 너무 많은 데이터를 사용해야 하는 상황에서는 시간이 너무 지연된다. 이럴 때는 점진적으로 학습하는 알고리즘을 사용해야 한다.
  - 온라인 학습 : 데이터를 미니 배치라고 부르는 작은 묶음 단위로 주입. 아주 큰 데이터 셋도 다룰 수 있으며, 점진적으로 학습하므로 시스템이 미니 배치에 따라 변화할 수 있다.

- 사례 기반 학습과 모델 기반 학습
  - 사례 기반 학습 : 기계가 샘플을 기억한다. 이후 새로운 데이터가 들어오면 그 사례와 같은, 혹은 비슷한 정도(유사도)를 측정하여 일반화한다.
  - 모델 기반 학습 : 기계가 샘플을 통해 새로운 모델을 생성, 이를 훈련(Training)이라고 한다. 이를 기준으로 새로운 데이터를 일반화한다. 모델에는 그 모양을 결정하는 __파라미터__ (parameter)가 있다. 또, 만들어진 모델을 실제 데이터와 비교하여 평가하기 위한 함수들이 있다. <br/>[효용 함수(utility function, 모델이 얼마나 좋은지 평가)과 __비용 함수__ (cost function, 모델이 얼마나 나쁜지 평가)]

<br/>

## 4) 머신러닝의 주요 도전 과제

1. 충분하지 않은 양의 훈련 데이터
2. 대표성 없는 훈련 데이터
3. 낮은 품질의 데이터
4. 관련 없는 특성
5. 과대 적합과 과소적합

- 훈련 데이터 과대적합(Overfitting) : 훈련 데이터에 '너무' 잘 맞아 일반성이 떨어지는 경우
  - 해결 방법 : 파라미터 수가 적은 모델 선택, 훈련 데이터에 있는 특성 수 축소, 모델에 제약 가하기 등의 방법을 통해 모델을 단순화 / 훈련 데이터를 더 많이 모으기 / 훈련 데이터의 노이즈 줄이기(이상치 제거 등)

- 훈련 데이터 과소적합(Underfitting)
  - 해결 방법 : 파라미터 수가 더 많은 모델 선택 / 학습 알고리즘에 더 좋은 특성 제공 / 모델의 제약 줄이기

<br/>

## 5) 테스트와 검증

![TrainTestSet](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Machine_learning_nutshell_--_Split_into_train-test_set.svg/640px-Machine_learning_nutshell_--_Split_into_train-test_set.svg.png)

모델이 얼마나 잘 만들어졌는지 알기 위해서는 데이터를 실제로 적용해봐야 한다. 그러나 가지고 있는 모든 데이터를 활용해 훈련을 한 후에 출시한 모델의 성과가 좋지 않다면 고객은 불만을 토로할 것. 그래서 가지고 있는 데이터를 훈련 세트(Training set)와 테스트 세트(Test set)으로 나눈다. (일반적으로는 데이터의 80%로 훈련 세트를 만들고 20%로는 테스트 세트를 만든다.)

하지만 테스트 세트도 1번만 사용 가능하기 때문에 테스트 세트 전에 모델을 시험해 볼 세트가 또 필요하다. 그것을 검증(Validation)세트라고 한다. (수능[Test set] 전에 모의고사[Validation set]를 보는 것과 같이.) 훈련 데이터의 일부분을 나누어 검증 세트를 만든다. 이 과정에서 검증 세트에 너무 많은 데이터를 할당하지 않기 위해 일반적으로 교차 검증 이라는 기법을 사용한다. (교차 검증에 대한 내용은 다음 게시물에 등장합니다.)

<br/>

※ 첫 단원부터 다양한 머신러닝 기법을 설명하면서 듣도 보도 못한 용어가 많이 등장하여 당황하신 분도 계실 것입니다. 이번 단원에서는 그냥 이런 기법들이 있다는 것, 그리고 이후에 등장한다는 것만 알아두시고 넘어가면 좋을 것 같습니다. 