---
layout: post
title: 3. Classification
category: Hands on Machine Learning
tag: Machine-Learning
---

 

## 1) MNIST

미국 고등학생과 인구조사국 직원들이 쓴 손글씨 데이터(0 부터 9 까지)이다. 총 데이터 셋의 개수는 7만 개이다. 6만 개를 훈련 세트로, 1만 개를 테스트 세트로 각각 할당한다.

```python
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```



<br/>

## 2) 이진 분류기

문제를 단순화해보자. 이를테면, 5인 것과 5가 아닌 것으로 분류하기로 하자. 이렇게 O와 X, 2개의 클래스로 분류하는 것을 이진 분류기(binary classifier)라고 한다. 본 문제에서는 이진 분류 모델로 확률적 경사 하강법(Stochastic Gradient Descent, SGD)을 사용한다. 사이킷런에서는 SGDClassifier를 제공한다.

```python
y_train_5 = (y_train == 5)
y_test_5 = (y_test == 5)

from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(max_iter=5, random_state=42)
sgd_clf.fit(X_train, y_train_5)
```



<br/>

## 3) 성능 측정

- 교차 검증을 사용한 정확도 측정

  - 교차검증 직접 구현하기 : 사이킷런이 제공하는 기능보다 교차 검증 과정을 더 많이 제어해야 할 필요가 있다. 이럴 때는 다음과 같은 코드로 cross_val_score() 함수를 직접 구현할 수 있다.

  ```python
  from sklearn.model_selection import StratifiedKFold
  from sklearn.base import clone
  
  skfolds = StratifiedKFold(n_splits=3, random_state=42)
  
  for train_index, test_index in skfolds.split(X_train, y_train_5):
      clone_clf = clone(sgd_clf)
      X_train_folds = X_train[train_index]
      X_train_folds = y_train_5[train_index]
      X_test_fold = X_train[test_index]
      X_test_fold = y_train_5[test_index]
      
      clone_clf.fit(X_train_folds, y_train_folds)
      y_pred = clone_clf.predict(X_test_fold)
      n_correct = sum(y_pred == y_test_fold)
      print(n_correct / len(y_pred))
  ```

  ※ (특히 불균형한 데이터에서는) __정확도를 분류기의 성능 측정 지표로 선호하지 않는다.__ 

- 오차 행렬 : 분류기의 성능을 평가하는 더 좋은 방법. '0'이 '1'로 잘못 분류된 횟수를 센다. 오차 행렬을 만들기 위해서는 실제 타깃과 비교할 수 있도록 먼저 예측값을 만들어야 한다. 사이킷런에서는 cross_val_predict() 함수를 제공한다.

  ```python
  from sklearn.model_selection import cross_val_predict
  y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
  
  from sklearn.metrics import confusion_matrix
  confusion_matrix(y_train_5, y_train_pred)
  >>[[53272, 1307]
     [ 1077, 4344]]
  ```

  - 오차 행렬의 행은 실제 클래스를 나타내고 열은 예측 클래스를 나타낸다.

  |              | 5 가 아닌 것으로 판단 | 5 로 판단 |
  | ------------ | --------------------- | --------- |
  | 실제로 5 (X) | 53272                 | 1307      |
  | 실제로 5 (O) | 1077                  | 4344      |
  
- 정밀도와 재현율

  - __정밀도__ (Precision)

  $$
  Precision = \frac{TP}{TP+FP}
  $$

  ​			$TP$ : 진짜 양성의 수,  $FP$ : 거짓 양성의 수

  - __재현율__ (Recall) : 민감도(sensitivity) 또는 진짜 양성 비율(true positive)이라고도 함
  
  $$
  Recall = \frac{TP}{TP+FN}
  $$

  ​	$FN$ : 거짓 음성의 수

  - __F1 점수__ (F1 Score) : 정밀도와 재현율의 조화평균으로 구해진다
  
  $$
F = \frac{2}{(1/Precision)+(1/Recall)} = \frac{TP}{TP+\frac{FN+FP}{2}}
  $$

  사이킷런에서는 F1 점수를 계산하는 f1_score() 함수를 제공한다.
  
  ```python
  from sklearn.metrics import f1_score
f1_score(y_train_5, y_train_pred)
  ```
  
  - __정밀도/재현율 트레이드오프__ : 정밀도를 올리면 재현율이 줄고, 재현율을 높이면 정밀도가 내려가기 마련. 특정 수치가 강조되어야 할 경우에는 분류의 결정 임곗값(Threshold)을 설정하여 정밀도 또는 재현율의 수치를 확보할 수 있다. 사이킷런의 분류 알고리즘은 개별 레이블 별로 결정 확률을 구한 후, 예측 확률이 큰 쪽을 예측하게 된다. (이진 분류기의 경우 50:50.) 사이킷런에서는 예측 확률을 반환하는 predict_proba() 메서드를 제공한다.  



- __ROC 곡선__ (Receiver Operating Characteristic, 수신기 조작 특성) : 이진분류에서 널리 사용된다. 정밀도/재현율 곡선과 비슷하지만 다르다.

  - 거짓 양성 비율(FPR)에 대한 진짜 양성 비율(TPR, 재현율)의 곡선. 음성으로 정확하게 분류한 음성 샘플의 비율으로 구한다. FPR은 1에서 진짜 음성 비율(TNR, 특이도)을 뺀 값과도 같다.
  
  $$
  ROC\quad Curve = \frac{TPR}{FPR} = \frac{TPR}{1-TNR}
  $$
  
  - **AUC** : ROC 곡선 아래의 면적을 AUC라고 한다. 완전 랜덤한 분류기의 AUC는 0.5이며 완벽한 분류기의 AUC는 1이다. 
  
  ![AUC](https://t1.daumcdn.net/cfile/tistory/262E8E3F544837AD27)
  
  

<br/>

## 4) 다중 분류

다중 분류기는 둘 이상의 클래스를 구분할 수 있다. 다중 분류기는 크게 두 가지로 나뉨

- 여러 개의 클래스를 직접 처리할 수 있는 다중 분류기 : 랜덤 포레스트, 나이브 베이즈 등

- 이진 분류만 가능한 가능한 분류기 : 서포트 벡터 머신(SVM), 선형 분류기 등

  - 일대다(One-versus-All, OvA) 전략 : 특정 클래스 하나만 구분하는 이진 분류기 10개를 훈련시켜 결정 점수 중에서 가장 높은 클래스를 선택하는 방법
  - 일대일(One-versus-One, OvO) 전략 : 각 클래스의 조합마다 이진 분류기를 훈련시키는 것. 클래스가 $N$ 개일 경우 $N*(N-1)/2$ 개의 이진 분류기가 필요함.
  - SVM 같은 특정 이진 분류 알고리즘은 훈련 세트의 크기에 민감하기 때문에 훈련 세트가 작은 OvO를 선호하지만, 대부분의 이진분류 알고리즘은 OvA를 선호한다. 사이킷런에서 OvO나 OvA를 사용하도록 강제하려면 OneVsOneClassifier나 OneVsRestClassifier를 사용한다. 예를 들어, SGDClassifier로 OvO 전략을 사용하고자 한다면 다음과 같은 코드를 사용하면 된다.

  ```python
  from sklearn.multiclass import OneVsOneClassifier
  ovo_clf = OneVsOneClassifier(SGDClassifier(max_iter=5, random_state=42))
  ovo_clf.fit(X_train, y_train)
  ```

만약 샘플을 바로 다중 클래스로 분류할 수 있는 랜덤 포레스트 같은 경우에는 OvO나 OvA를 적용할 필요가 없다. predict_proba() 메서드를 호출하면 분류기가 각 샘플에 부여한 클래스별 확률을 얻을 수 있음.

```python
forest_clf.fit(X_train, y_train)
```



<br/>

## 5) 에러 분석

모델의 성능을 향상시키기 위해 에러의 종류를 분석.

- 오차 행렬 살펴보기

```python
y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)
#X_train_scaled는 X_train을 StandardScaler()로 표준화를 진행한 데이터
conf_mx = confusion_matrix(y_train, y_train_pred)
```

오차 행렬을 분석하여 분류기의 성능 향상 방안에 대한 통찰을 얻는다. 분류가 잘 되지 않는 클래스가 어떤 것인지 확인하고, 그 클래스에 해당하는 데이터를 더 모으거나 분류기에 도움 될 만한 특성을 더 찾아볼 수 있다. 

<br/>

## 6) 다중 레이블 분류

 분류기가 샘플마다 여러 개의 클래스를 출력해야 하는 경우도 있음. 여러 명이 등장하는 사진에 어떤 사람이 있는지 판단하기 위해서는 한 장의 사진에 여러 개의 레이블을 할당해야 함. MNIST 예제로 다중 레이블 분류의 예를 살펴보자.

```python
from sklearn.neighbors import KNeighborsClassifier
y_train_large = (y_train >= 7)
y_train_odd = (y_train % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]
# 해당 손글씨가 7보다 큰 숫자를 쓴 것인지, 그리고 홀수를 쓴 것인지 동시에 판단
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)
```

<br/>

## 7) 다중 출력 분류

**다중 출력 다중 클래스 분류** (다중 출력 분류) : 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화한 것. MNIST 이미지의 노이즈를 제거하는 시스템을 만든다고 해보자. 분류기의 출력이 다중 레이블(1픽셀당 1레이블)이고 각 레이블은 여러 개의 값(0~255의 픽셀 농도)을 가짐. 그러면 이 시스템은 다중 출력 분류 시스템이 되어야 한다.

:black_nib: 이 예시에서처럼 분류와 회귀 사이의 경계는 때때로 모호. 레이블의 픽셀 농도는 분류보다 회귀와 비슷. 게다가 다중 출력 시스템이 분류 작업에 국한되지도 않음.