---
layout: post
title: 7. 딥러닝(CV)
category: Deep Learning
tag: Deep-Learning
---



## 1) 더 깊게

- 앞에서 제시된 것보다 더 깊은 VGG라는 모델을 참조하여 손글씨를 분류하는 CNN을 구성해보자. 이 모델의 특징은 다음과 같다.
  - 3X3 크기의 작은 필터를 사용한 합성곱 계층
  - 활성화 함수로 ReLU 사용
  - 완전연결 계층 뒤에 드롭아웃 계층 사용
  - Optimizer로 Adam을 사용
  - 가중치 초깃값으로 He초깃값 사용



- <What is the class of this image?> 참조하기 : 이 웹 사이트에서는 이미지 분류 모델의 성능을 비교한 것을 볼 수 있다. 이들 중 상위에 랭크된 모델을 참고하면 정확도를 더 높일 수 있다. 이들 모델에서는 앙상블 학습, 학습률 감소, 데이터 증식(증강, 확장) 등을 통해 더 높은 정확도를 달성하고 있다. 특히 데이터 증식은 비교적 쉽게 정확도를 높일 수 있는 방법이다. 
  - **데이터 증식(Data Augmentation)** : 입력 이미지를 알고리즘을 동원해 인위적으로 증식시키는 방식이다. 입력 이미지를 평행 이동하거나 회전하는 등 미세한 변화를 주어 이미지의 개수를 늘려나간다. 이외에도 이미지 자르기(crop), 뒤집기(flip), 밝기 변화, 확대 및 축소 등 다양한 방법을 통해 다양한 이미지를 생성할 수 있다.



- 왜 층을 깊게할까
  - 신경망 매개변수의 수가 줄어들기 때문이다. 층을 깊게 하면 적은 매개변수로도 높은 수준의 표현력을 달성할 수 있다. 한 개의 층에서 5X5 합성곱을 한 번 사용하여 하나의 출력값을 내는 경우를 생각해보자. 그리고 두 개의 층에서 3X3 합성곱을 두 번 사용하여 5X5 크기의 데이터에서 하나의 출력값을 내는 경우를 생각해보자. 두 경우에서 학습하는 데이터의 크기는 동일하지만 전자는 필요한 매개변수의 개수가 25개(5X5)인 반면 후자는 18개(2X3X3)이다. 이 차이는 층이 깊어질수록 커지기 때문에 큰 데이터를 학습하기 위해서는 층을 깊게하는 것이 유리하다. 예를 들어 9X9 크기의 데이터를 학습하는데 9X9 크기의 합성곱을 사용하면 81개(9X9)의 매개변수가 필요하고 3X3 크기의 합성곱을 4층으로 구성할 경우 36개(4X3X3)의 매개변수가 필요한 것을 볼 수 있다.
  - 학습의 효율성이 높아지기 때문이다. 신경망이 얕은 경우에는 한 번에 최대한 많은 정보를 추출해내야 한다. 층이 깊어지면 한 층에서 학습해야 하는 정보의 양이 줄어들기 때문에 학습 시간이 더욱 빨라지게 된다. 게다가 층을 깊게 하면 정보를 계층적으로 전달할 수도 있다는 장점이 있다. 



<br/>

## 2) 딥러닝의 초기 역사

- **이미지넷(ImageNet)** : 이미지넷은 100만 장이 넘는 이미지를 담고 있는 데이터셋이다. 레이블이 포함된 다양한 종류의 이미지 데이터로 구성되어 있다. 매년 열리는 대회인 ILSVRC에서는 이미지넷 데이터셋을 사용하여 더 좋은 모델을 경쟁한다. ILSVRC의 분류 부문에서 2012년이 AlexNet이 우승한 이래로 Clarifi(2013), VGG(2014), GoogLeNet(2015), ResNet(2016) 등 딥러닝 모델이 좋은 성능을 기록하고 있다.



- **VGG** : VGG는 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN이다. 다만 이전보다 층을 더 깊게 구성한 것이 특징이다. VGG16은 총 16층, VGG19은 총 19층으로 구성된다. VGG는 이후의 모델보다 성능이 떨어지기는 하지만 층의 구조가 비교적 단순하기 때문에 많은 사람들이 VGG를 응용하여 사용한다. 아래는 VGG16을 이미지로 나타낸 것이다.

<p align='center'><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FK990l%2FbtqwDJ7C54R%2F664Ksm6gyTGBR1wK3YPDFk%2Fimg.png" alt="VGG16" style="zoom:50%;" /></p>



- **GoogLeNet** : GoogLeNet도 기본적인 CNN 형태로 구성되어 있다. 다만 세로 방향의 깊이뿐만 아니라 가로 방향도 깊다는 것이 특징이다. 가로 방향으로 구성한 구조를 인셉션 구조라고 한다. GoogLeNet의 인셉션 구조는 크기가 다른 필터와 풀링을 병렬적으로 적용하여 그 결과를 조합한다. 아래 그림에서 파란색의 층은 필터가 적용되는 뉴런이며, 빨간 색은 풀링을 하는 뉴런이다.

![GoogLeNet](https://miro.medium.com/max/2588/1*ZFPOSAted10TPd3hBQU8iQ.png)



- **ResNet** : ResNet은 **스킵 연결(Skip Connection)** 이라는 기술을 적용하여 성능 향상을 한다. 딥러닝 모델은 일정 시점까지는 층이 깊어질수록 성능이 좋아지지만, 너무 층이 깊어지면 오히려 성능이 떨어지게 된다. 스킵 연결은 층의 깊이에 비례해 성능을 향상시킬 수 있도록 한다.

<p align="center"><img src="https://kharshit.github.io/img/resnet_block.png" alt="Skip Connection" style="zoom: 80%;" /></p>

입력 $x$ 를 연속한 두 합성곱 계층을 뛰어넘어 출력에 바로 연결한다. 스킵 연결이 없다면 층의 출력이 $F(x)$ 가 되어야 하지만 스킵 연결을 통해 넘어온 $x$ 를 더하여 해당 층의 최종 출력은 $F(x) + x$ 가 된다. 스킵 연결은 순전파 뿐만 아니라 역전파시에도 동일하게 적용되어 ( $x$ 자체를 넘겨줌) 앞 층에 너무 작거나 크지 않은 그래디언트를 보내줄 수 있다. 층을 깊게 할수록 기울기가 작아지는 문제를 이 스킵 연결이 해결해준다. 아래는 ResNet의 이미지다.

![ResNet](https://developer.ridgerun.com/wiki/images/f/f5/Resnet_architecture.png)

위 그림에서 볼 수 있듯 ResNet은 VGG를 기반으로 하고 있으며 스킵 연결을 통해 층을 깊게 했다. ResNet을 포함하여 ImageNet으로 학습한 위 모델들은 실제 제품에 활용해도 높은 성능을 보이고 있다. 이를 **전이 학습(Transfer Learning)** 이라고 하며 확보된 데이터셋이 적을 경우 이 방법을 활용해 좋은 성능의 모델을 활용할 수 있다.



<br/>

## 3) 딥러닝 고속화

- 풀어야 할 숙제 : 순전파에서 각 층이 소비하는 시간을 시각화해보자. AlexNet을 기준으로 합성곱 계층에서 약 90% 내외의 시간이 소요되는 것을 알 수 있다. 합성곱 계층의 연산을 어떻게 빠르게 하느냐가 전체 모델의 속도를 결정.
- GPU를 활용한 고속화 : GPU는 병렬 수치 연산을 고속으로 처리할 수 있다. 때문에 GPU컴퓨팅을 사용하면 CPU보다 시간을 수 배 가량 줄일 수 있다.
- 분산 학습 : 딥러닝 계산의 시간을 더욱 줄이기 위해 다수의 GPU로 계산을 분산하기도 한다. 텐서플로(Tensorflow)를 포함해 다양한 딥러닝 프레임워크가 분산학습에 중점을 두고 개발하고 잇음.
- 연산 정밀도와 비트 줄이기
  - 메모리 용량 : 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야 하므로 가급적이면 많은 메모리를 확보하는 것이 병목 현상을 줄이는 한 가지 방법이다. 컴퓨터에서는 일반적으로 64비트나 32비트 부동소수점을 사용한다. 하지만 딥러닝 연산은 높은 수치의 정밀도를 요구하지 않으므로 (메모리 용량을 확보하기 위해) 최대한 비트를 줄여 표현한다. 밝혀진 바로는 **16비트 반정밀도** 를 사용하여 연산하여도 큰 문제가 없는 것으로 알려져 있다.

<br/>

## 4) 딥러닝의 활용

- 사물 검출 : 이미지 속에 담긴 사물의 위치와 종류(클래스)를 알아내기 위한 기술
  - R-CNN(Regions with Convolutional Neural Network) : 사물 검출을 수행하기 위한 방식 중 하나
    - 이미지 입력 - 후보 영역 추출 - CNN으로 특징을 계산 - 영역 분류 의 과정으로 이루어져 있다.
    - 일반적인 CNN과 다르게 미리 후보 영역(Region)을 추출하여 클래스를 분류한다. 영역을 추출하면서 SVM을 사용하는 등 실제 처리 흐름은 복잡하다. 
    - 최근에는 후보 영역마저 CNN으로 추출하는 [Faster R-CNN](https://arxiv.org/abs/1506.01497) 도 등장(2015).
- 분할(Segmentation) : 이미지를 픽셀 수준에서 분류하는 문제. 
- 사진 캡션 생성



## 5) 딥러닝의 미래

- 이미지 스타일(화풍) 변환
- 이미지 생성
- 자율 주행
- Deep Q-Network(강화학습)