---
layout: post
title: 2. End to End ML Project
category: Hands on Machine Learning
tag: Machine-Learning
---

 

## 1) 큰 그림 보기

- 비즈니스의 문제는 무엇이고, 현재 솔루션은 어떻게 구성되어 있는가?

- 어떤 방법을 사용할 것인가?  지도/비지도/강화 학습 중 어떤 것인가? (만약 지도학습이라면) 분류인가 회귀인가?  배치/온라인 학습 중 어떤 것을 사용할 것인가?

- 성능 측정 지표는 무엇인가? (회귀 문제에서) 많이 사용되는 성능 측정 지표(RMSE, MAE) 중 어떤 것인가?

  - __평균 제곱근 오차__ (Root Mean Square Error, RMSE)

  $$
  RMSE(\mathbb{X},h) = \sqrt{\frac{1}{m}\sum_i^m(h(\mathbb{X^i}-y^i))^2}
  $$

  $m$ : 측정 데이터셋에 있는 샘플 수

  $\mathbb{X}^i$ : i 번째 샘플의 전체 특성값 벡터 (레이블 제외)

  $y^i$ : 해당 레이블(샘플의 기대 출력값)

  $h$ : 시스템의 예측 함수, 가설이라고도 함

  $RMSE(\mathbb{X},h)$ 는 가설h를 사용하여 샘플을 평가하는 __비용함수(Cost Function)__

  - __평균 절대 오차__ (Mean Absolute Error, MAE) : 이상치로 보이는 구역이 많은 경우에 사용할 수 있다.

  $$
  MAE(\mathbb{X},h) = \frac{1}{m}\sum_i^m|h(\mathbb{X^i}-y^i)|
  $$

  RMSE와 MAE 모두 예측값의 벡터와 타깃값의 벡터 사이의 거리를 재는 방법. 다만 둘의 거리 측정 방법인 노름(norm)이 다르다. 노름에 대한 정보는 [김태완님 블로그](http://taewan.kim/post/norm/) 를 참조하자.

<br/>

## 2) 데이터 가져오기

- 데이터를 가져오고 훑어보자. (블로그 내의 [Pandas Basic](https://yngie-c.github.io/python/2020/01/29/pandasbasic/) 참조)
- 데이터 세트를 훈련 세트(Train set)와 테스트 세트(Test set)로 나눈다. (Train-Test Split, 기억이 나지 않는다면[이전 게시물]([https://yngie-c.github.io/hands%20on%20machine%20learning/2020/01/28/homl1_1/](https://yngie-c.github.io/hands on machine learning/2020/01/28/homl1_1/)) 의 마지막 부분을 참조해도 좋습니다.)

<br/>

## 3) 데이터 이해를 위한 탐색과 시각화

- 무작정 시각화 해보기
- 연속형 변수에 대한 상관관계 조사
  - 상관계수에 대한 내용은 [여기](https://mansoostat.tistory.com/115) 를 참조하도록 하자. 일반적으로는 피어스만 상관계수를 사용한다.
- 특성을 조합하여 새로운 특성 만들기를 시도해보자.

<br/>

## 4) 머신러닝 알고리즘을 위한 데이터 준비

- 데이터 정제 : NaN값 처리하기

  - 해당 구역을 삭제하는 방법 -  .dropna()
  - 전체 특성을 삭제하는 방법 -  .drop()
  - 특정 값으로 채우는 방법(0, 평균, 중간값 등) - .fillna()
  - 사이킷런에서는 Imputer를 사용하여 NaN값을 쉽게 다룰 수 있다.

  ```python
  from sklearn.preprocessing import Imputer
  
  imputer = Imputer(strategy="median")
  imputer.fit(df)
  #df의 특성이 수치형일 경우에만 사용할 수 있다.
  ```

- 텍스트와 범주형 특성 다루기

  - 범주형 특성을 어떻게 다룰 수 있을까?

  ```python
  df_reg = df['region']
  #'region'에는 '서울', '인천', '경기', '대전', '충남', '충북', '강원'이 있다고 가정하자.
  df_reg.head(10)	
  > '서울' '대전' '서울' '인천' '대전' '대전' '서울' '인천' '인천' '경기'
  
  #일 때, pandas의 .factorize() 메서드를 사용하면 각 카테고리가 정수 값으로 매칭된다.
  df_reg_encoded = df_reg.factorize()
  df_reg_encoded[:10]
  > array([0, 1, 0, 2, 1, 1, 0, 2, 2, 3])
  
  #이렇게 되면 기계는 자신과 가까운 값을 더 비슷하다고 생각하게 됨. ex) '서울-대전'을 '서울-인천','서울-경기'보다 유사하다고 여기게 된다. 하지만 실제로는 그렇지 않은 경우가 많다. 그래서 등장하게 된 것이 원-핫 인코딩이다.
  ```

  - __원-핫 인코딩(one-hot encoding)__ : 범주형 특성의 값이 정해질 때 1이 되고, 다른 값이 0이 되도록 한다. 위의 예를 원-핫 인코딩으로 표현해보자. 사이킷런에서는 OneHotEncoder를 통해 숫자로 된 범주형 값을 원-핫 벡터로 바꿀 수 있다.

  ```python
  #df_reg.head(10)을 원-핫 인코딩으로 표현한 후 toarray()를 사용해 넘파이 배열로 변형하면 다음과 같은 결과가 나온다.
  
  from sklearn.preprocessing import OneHotEncoder
  encoder = OneHotEncoder()
  df_reg_1hot = encoder.fit_transform(df_reg_encoded)
  df_reg_1hot.toarray()
  >[[1, 0, 0, 0, 0, 0, 0],
    [0, 1, 0, 0, 0, 0, 0],
    [1, 0, 0, 0, 0, 0, 0],
    [0, 0, 1, 0, 0, 0, 0],
    ...
    [0, 0, 1, 0, 0, 0, 0],
    [0, 0, 0, 1, 0, 0, 0]]
  ```

- 특성 스케일링 : 머신러닝 알고리즘은 숫자 특성들의 스케일이 많이 다르면 잘 작동하지 않는다. 따라서 값들의 스케일이 많이 차이나는 경우 특성의 범위를 통일하기 위한 방법을 사용한다.

  - min-max 스케일링(정규화, normalization) : 사이킷런에서는 MinMaxScaler 변환기를 제공한다. feature_range 매개변수를 따로 설정하여 설정 범위를 (0,1)에서 다른 것으로 바꿀 수도 있다.

  $$
  Normalization = \frac{\bar{X} - X_{min}}{X_{max}-X_{min}}
  $$

  - 표준화(Standardization) : 범위의 상한과 하한이 없기 때문에 특정 알고리즘에는 문제가 될 수 있다. 하지만 이상치에 영향을 덜 받게 된다. 사이킷런에서는 StandardScaler 변환기가 있다.

  $$
  Z = \frac{\bar{X}-m}{\sigma}
  $$

  

<br/>

## 5) 모델 선택과 훈련



<br/>

## 6) 모델 세부 튜닝



<br/>

## 7) 론칭, 모니터링, 그리고 시스템 유지 보수

