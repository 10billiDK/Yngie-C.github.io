---
layout: post
title: 최대 우도 추정 & 최대 사후 확률 추정 (MLE & MAE)
category: Machine Learning
tag: Machine-Learning
---

본 포스트는 [문일철 교수님의 인공지능 및 기계학습 개론 I](https://www.edwith.org/machinelearning1_17/joinLectures/9738) 강의를 바탕으로 작성하였습니다.



# 최대 우도 추정

본 챕터에서는 **최대 우도 추정(Maximum Likelihood)** 에 대해서 알아보겠습니다. 최대 우도 추정을 알기위해 필요한 이항 분포(Binomial distribution)에 대해서 알아봅시다.



## Binomial Distribution(이항 분포)

아래와 같이 생긴 압정을 던져 가운데 압정처럼 뒤집어진 모양이 나올지, 아니면 양 옆에 위치한 압정처럼 엎어진 모양이 나올지를 예측하는 게임을 한다고 가정해봅시다. 이 때 편의상 엎어진 모양을 머리(Head, H)라고 하고 뒤집어진 모양을 꼬리(Tail, T)라고 표현합니다.

<p align="center"><img src="https://live.staticflickr.com/4106/4983417622_e29e2c3008_b.jpg" alt="thumbtack" style="zoom:50%;" /></p>

<p align="center" style="font-size:80%">이미지 출처 : <a href="https://www.flickr.com/photos/22994840@N03/4983417622/sizes/l/">flicker.com</a></p>

이 게임을 할 때 압정을 던지는 행위는 연속적(Continuous)이지 않습니다. 던지는 횟수가 1.123...번, 3.1415... 번과 같이 될 수 없고 1번, 2번, 3번 ... 과 같이 일종의 마디를 가지고 증가하기 때문입니다. 그렇기 때문에 이 게임에서 압정을 던지는 행위는 이산적(Discrete)이라고 할 수 있습니다. 그리고 이산적인 행위에서 특정 사건이 발생할 확률의 분포를 **이산 확률 분포(Discrete probability distribution)** 라고 합니다.

그리고 이 게임에서 발생할 수 있는 사건은 오직 머리(H)와 꼬리(T), 즉 사건의 개수는 '2' 입니다. 압정을 던지는 게임처럼 2가지 사건만을 가지는 것을 베르누이 시행(Bernoulli trial)이라고 부릅니다. 동전의 앞과 뒤, 특정 미션에 대한 성공 혹은 실패 등 다양한 상황에서 베르누이 시행을 찾아볼 수 있습니다.

이번에는 **독립 항등 분포(independent and identical distributed, i.i.d)** 에 대해서 알아봅시다. 단어의 듯에서도 알 수 있듯이 i.i.d는 독립적이며 동일한 확률 분포를 가지는 조건을 말합니다. 압정을 던지는 게임도 i.i.d 조건을 만족합니다. 압정을 한 번 던져 나온 사건의 결과는 이후 사건에 영향을 주지 않기 때문에 독립적(Independent)이라고 할 수 있습니다. 또한 압정을 던지는 행위의 확률 분포는 언제나 고유하기(Identical) 때문입니다.

위와 같은 것들이 가정되었다면 이 게임에서 특정 사건이 발생할 확률을 알 수 있습니다. 예를 들어, 압정을 5번 던져 (머리, 머리, 꼬리, 머리, 꼬리)가 나왔다고 합시다. 압정을 한 번 던져 머리가 나올 확률 $P(H) = \theta$ 라고 하면 (머리, 머리, 꼬리, 머리, 꼬리)의 순서대로 나타날 확률은 아래와 같이 나타낼 수 있습니다.


$$
P(HHTHT) = \theta \cdot \theta \cdot (1-\theta) \cdot \theta \cdot (1-\theta) = \theta^3 (1 - \theta)^2
$$


이를 일반화하면 $\theta$ 가 주어졌을 때 해당 데이터셋(Dataset) $D$ 가 발생할 확률인 $P(D \vert \theta)$ 로 나타낼 수 있습니다. 아래 식에서 $\alpha_H, \alpha_T$ 는 데이터셋 $D$ 에서 머리(H)와 꼬리(T)가 각각 발생한 횟수입니다.
$$
P(D|\theta) = \theta^{\alpha_H}(1 - \theta)^{\alpha_T}
$$
위 식은 $HHTHT$와 같이 정해진 순서대로 나왔을 때의 확률을 일반화하여 나타낸 것입니다. 그렇다면 순서에 상관없이 머리와 꼬리가 나타날 확률은 어떻게 구할 수 있을까요? 위에서 나타냈던 특정 한 사건(여기서는 머리)이 발생할 확률 $\theta$ 를 $p$로, 그 사건이 $\alpha_H$ 를 $k$ 로 바꿔줍시다. 그러면 임의의 순서대로 구성된 $n$ 개의 사건 세트에서 발생할 확률이 $p$ 인 특정 한 사건이 $k$ 번 나올 확률을 아래와 같은 함수 $f$ 로 나타낼 수 있습니다. 

$$
f(k;n,p) = P(K=k) = \left(\begin{array}{c}n\\k\end{array}\right) p^k (1-p)^{n-k}  \\
\because \left(\begin{array}{c}n\\k\end{array}\right) = \frac{n!}{k!(n-k)!}
$$



## Maximum Likelihood Estimation(최대 우도 추정)

특정 데이터셋으로부터 사건이 일어날 확률을 구하는 것은 중요합니다. 압정 게임이든 내일 비가 올 지 맑을지 예측하든 확률을 알아야 그에 맞춰 행동할 수 있기 때문입니다. 그렇다면 데이터셋 $D$ 로부터 압정 게임에서 머리(H)가 발생할 확률 $p$ 는 어떻게 추정할 수 있을까요? 우리가 알아볼 **최대 우도 추정(Maximum Likelihood Estimation)** 은 확률 $p$ 추정하기 위한 하나의 방법입니다. 최대 우도 추정은 말 그대로 현재 가지고 있는 데이터셋이 나올 확률을 최대화하는 우도(Likelihood) $\theta$ 를 구하는 것입니다. 아래 그래프는 최대 우도 추정을 설명하기 위한 그래프입니다. 수식으로는 아래와 같이 나타낼 수 있습니다.



$$
\hat{\theta} = \text{argmax}_{\theta} P(D \vert \theta)
$$

위 식에서 $\hat{\theta}$ 는 $P(D \vert \theta)$ 를 최대로 하는 $\theta$ 입니다. 예를 들어, 특정 사건의 확률 $\theta$ 가 [0,1] 사이의 범위일 때 특정 데이터셋 $D$ 가 나올 확률 $P(D \vert \theta)$ 가 아래 그래프의 붉은 곡선과 같다고 합시다. (주어지는 데이터셋 $D$ 에 따라 그래프의 모양은 달라질 수 있습니다.) 

<img src="https://i.stack.imgur.com/Mmals.png" alt="mle_graph" style="zoom:67%;" />

<p align="center" style="font-size:80%">이미지 출처 : <a href="https://stats.stackexchange.com/questions/166558/interpretation-maximum-likelihood-plot">Stackoverflow.com</a></p>

최대 우도 추정은 위 그래프에서 확률이 최대인 점의 $\theta$ 를 찾는 과정입니다. 주어진 데이터셋에 가장 Fit한 $\theta$ 를 찾는 과정이라고 말할 수 있겠습니다. 위에서 알아본 식을 다음과 같이 나타낼 수 있습니다.

$$
\hat{\theta} = \text{argmax}_{\theta} P(D \vert \theta) = \text{argmax}_{\theta} \theta^{\alpha_H}(1 - \theta)^{\alpha_T} \\
\hat{\theta} = \text{argmax}_{\theta} \ln P(D \vert \theta) = \text{argmax}_{\theta} \{ \alpha_H \ln \theta + \alpha_T \ln (1 - \theta) \}
$$


위 첫 번째 식에서 구한 $\hat{\theta}$ 과 두 번째 식에서 구한 $\hat{\theta}$ 은 동일합니다. 로그 함수 $(\ln)$ 은 $[0,1]$ 에서 단조 증가 함수[^1] 이므로 $\text{argmax}$ 이후의 식에 함수를 취해주어도 변화하지 않습니다. 우리의 목표는 $\text{argmax}$ 이후에 위치한 식이 최댓값일 때의 $\theta$ 를 찾는 것입니다. 특정 함수의 도함수가 0이되는 지점이 있다면 그 점이 원래 함수의 최댓값 혹은 최솟값일 가능성이 있습니다. 그렇기 때문에 식을 미분한 후, 미분한 식의 값이 0이 되는 $\theta$ 를 구할 수 있습니다.


$$
\frac{d}{d\theta}(\alpha_H \ln \theta + \alpha_T \ln (1 - \theta)) = \frac{\alpha_H}{\theta} - \frac{\alpha_T}{1 - \theta} = 0 \\
\theta = \frac{\alpha_H}{\alpha_H + \alpha_T} \\
\therefore \quad \hat{\theta}_{MLE} = \frac{\alpha_H}{\alpha_H + \alpha_T}
$$


이제 최대 우도 추정을 통해 특정 데이터셋이 주어졌을 때 그 데이터셋이 일어날 확률을 최대로 하는 특정 사건이 일어날 확률 $\theta$ 를 구해낼 수 있게 되었습니다.



## Simple Error Bound(오차 범위)

위에서 알아본 바에 따르면 $\hat{\theta}$ 에 영향을 미치는 것은 $\alpha_H$ 과 $\alpha_T$ 의 비율입니다. 전체 횟수인 $n$ 이 커지더라도 이 비율만 지켜진다면 $\hat{\theta}$ 은 동일하게 됩니다.

동일한 비율을 가진 두 개의 데이터셋을 예로 들어봅시다. 한 데이터셋은 5번 던져 머리가 3번, 꼬리가 2번 나왔다고 합니다. 나머지 하나의 데이터셋은 50번 던져 머리가 30번, 꼬리가 20번 나온 경우입니다. 두 데이터셋 모두 최대 우도 추정을 통해 사건의 확률을 구하면 $\hat{\theta} = 0.6 = 3/(3+2) = 30/(30+20)$ 입니다. 그렇다면 두 데이터셋은 아무런 차이가 없는 것일까요? 데이터셋이 가지는 비율만 일정하다면 더 큰 데이터셋이 주는 이점은 없을까요?

질문에 대한 답은 "아니다"입니다. 일단 우리가 지금까지 알아본 $\hat{\theta}$ 은 그저 추정값일뿐 실제 확률이 아닙니다. 추정값은 언제나 실제값과 오차가 있기 마련입니다. 오차는 둘 사이의 차이이므로 절댓값을 활용하여 $\vert \hat{\theta} - \theta^\* \vert$ 로 나타낼 수 있습니다. 수학자들은 이 오차에 수학적 기술을 적용하여 **오차의 범위(Error bound)** 를 구하는 식을 만들어 놓았습니다. 오차의 범위를 구하는 식은 아래와 같습니다.


$$
P(\vert \hat{\theta} - \theta^* \vert \geq \epsilon ) \leq 2e^{-2N \epsilon^2} \\
\because N = a_H + a_T
$$


위 식을 보면 오차가 임의의 작은 값 $\epsilon$ 보다 커질 확률은 $2e^{-2N \epsilon^2}$ 로 나타납니다. 즉, $\epsilon$ 이 동일한 조건에서는 실행횟수 $N$ 이 증가할수록 오차의 범위가 줄어들게 된다는 의미입니다. 이러한 학습 방식을 팩 학습(Probably Approximate Correct learning, PAC learning)이라고 합니다. PAC learning의 목적은 높은 확률(Probably)로 낮은 오차 범위(Approximately Correct)를 갖도록 하는 것입니다. 즉 이를 달성하기 위해서는 데이터셋이 많아야 하고, 향후 머신러닝에서 커다란 데이터셋이 중요한 이유도 이 때문입니다.



# 최대 사후 확률 추정

## 사전 지식 포함시키기

지금까지 최대 우도 추정에 대해 알아보았습니다. 하지만 최대 우도 추정말고도 확률 $\theta$ 를 추정하기 위한 다른 관점의 방법이 있습니다. 이를 **최대 사후 확률 추정(Maximum a Posterior Estimation)** 이라고 합니다. 최대 우도 추정이 주어진 데이터셋 $D$ 가 나올 가능성을 최대로 하는 $\theta$ 를 구하는 것이었다면, 최대 사후 확률 추정은 말 그대로 사후 확률(Posterior)을 최대화 하는 과정입니다. 그렇기 때문에 최대 우도 추정에서는 사용하지 않았던 사전 지식(Prior knowledge)에 대한 Term이 추가됩니다. 아래는 베이즈 정리[^2]를 사용하여 사후 확률을 구하는 수식입니다.


$$
P(\theta \vert D) = \frac{P(D \vert \theta) P(\theta)}{P(D)} \\
\text{Posterior} = \frac{\text{Likelihood}\times \text{Prior Knowledge}}{\text{Normalizing Constant}}
$$




## 베이즈 관점에서 바라보기

위에서 구한 식에서 $P(D)$ 는 $P(\theta \vert D)$ 를 $[0,1]$ 사이의 값으로 만들어주기 위한 정규화 상수(Normalizing Constant) 입니다. 해당 상수는 사후 확률에 아무 영향을 주지 않기 때문에 $P(\theta \vert D) \propto P(D \vert \theta) P(\theta)$ 로 나타낼 수 있습니다.

그렇다면 사전 지식에 해당하는 $P(\theta)$ 는 어떻게 구할 수 있을까요? 압정을 던지는 행위와 같은 베르누이 시행이라면 베타 분포(Beta distribution)를 사용합니다. 베타 분포에 대한 더 자세한 이야기는 [확률 분포](https://yngie-c.github.io/machine learning/2020/04/04/prob_and_dist/) 에서 볼 수 있습니다. 여기서는 그냥 이 분포를 사용한다는 것만 알아두고 넘어가도록 합시다. 베타 분포를 사용하여 사전 확률 $P(\theta)$ 을 추정하면 다음과 같습니다. 



$$
P(\theta) = \frac{\theta^{\alpha-1}(1 - \theta)^{\beta-1}}{B(\alpha, \beta)} \\
B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)} ,\quad \Gamma(\alpha) = (\alpha-1)!
$$



## Maximum a Posteriori Estimation(최대 사후 확률 추정)

이제 $P(D \vert \theta) P(\theta)$ 식에서 각 항의 값을 알고 있으므로 아래과 같이 식을 정리할 수 있습니다.


$$
P(D \vert \theta) P(\theta) =  \theta^{\alpha_H}(1 - \theta)^{\alpha_T} \cdot \theta^{\alpha-1}(1 - \theta)^{\beta-1} = \theta^{\alpha_H + \alpha -1}(1 - \theta)^{\alpha_T +\beta-1}
$$


최대 사후 확률 추정에서 우리의 목표는 사후 확률인 $P(\theta \vert D)$ 를 최대화하는 것입니다. 수식으로는 $\text{argmax}$ 를 사용하여 아래와 같이 나타낼 수 있습니다.


$$
\hat{\theta} = \text{argmax}_{\theta} P(\theta \vert D)
$$


위에서 알아본 바와 같이 $P(D)$ 는 상수이므로 위 식을 아래와 같이 변형해주어도 $\hat{\theta}$ 의 값은 변하지 않습니다.


$$
\hat{\theta} = \text{argmax}_{\theta} P(D \vert \theta) P(\theta) \qquad \\
\qquad \quad = \text{argmax}_{\theta} [\theta^{\alpha_H + \alpha -1}(1 - \theta)^{\alpha_T +\beta-1}]
$$


이제부터는 최대 우도 추정에서 했던 과정을 동일하게 해주면 됩니다. $\text{argmax}$ 이하의 식에 로그를 취해준 뒤 미분하여 그 값이 0이 되는 $\theta$ 를 찾아줍니다.


$$
\hat{\theta} = \text{argmax}_{\theta} [\theta^{\alpha_H + \alpha -1}(1 - \theta)^{\alpha_T +\beta-1}] \qquad \qquad \qquad \\
= \text{argmax}_{\theta} \ln [\theta^{\alpha_H + \alpha -1}(1 - \theta)^{\alpha_T +\beta-1}] \qquad \qquad \\
\qquad \qquad = \text{argmax}_{\theta}[(\alpha_H + \alpha -1) \ln \theta + (\alpha_T +\beta-1) \ln (1 - \theta)]
$$

$$
\frac{d}{d\theta}[(\alpha_H + \alpha -1) \ln \theta + (\alpha_T +\beta-1) \ln (1 - \theta)] = 0\\
\frac{(\alpha_H + \alpha -1)}{\theta} - \frac{(\alpha_T + \beta -1)}{1-\theta} = 0 \\
$$

마지막 방정식 $\theta$ 에 관해서 정리하면 아래와 같다


$$
\hat{\theta}_{MAP} = \frac{\alpha_H + \alpha -1}{\alpha_H + \alpha + \alpha_T +\beta - 2}
$$


최대 우도 추정과 최대 사후 확률 추정을 통해 추정한 특정 사건의 확률 $\theta$ 는 비슷한 모양새를 띠고 있지만 완전히 같지는 않습니다. 베타 분포 내의 상수가 $\alpha=\beta=1$ 일 경우에만 서로 같아집니다. 하지만 시행 횟수 $N$ 이 커지면, 데이터셋의 크기가 커질수록 상수인 $\alpha, \beta$ 에 비해 $\alpha_H , \alpha_T$ 가 커지게 됩니다. 그렇기 때문에 $N$ 이 커질수록 최대 우도 추정으로 구한 $\theta$ 와 최대 사후 확률 추정으로 구한 $\theta$ 가 비슷해집니다.



[^1]: 수학에서, **단조 함수는 주어진 순서를 보존하는 함수** 이다. 기하학적으로, 실수 단조 함수의 그래프는 왼쪽에서 오른쪽으로 줄곧 상승하거나 줄곧 하강한다. 대수학적으로, 단조 함수는 두 순서 집합 사이의 준동형이다. ( 출처 - [위키백과 : 단조함수](https://ko.wikipedia.org/wiki/단조함수) )
[^2]: 확률론과 통계학에서, **베이즈 정리** (Bayes’ theorem)는 두 확률 변수의 사전 확률과 사후 확률사이의 관계를 나타내는 정리다. 베이즈확률론 해석에 따르면 베이즈 정리는 사전확률로부터 사후확률을 구할 수 있다. ( 출처 - [위키백과 : 베이즈 정리](https://ko.wikipedia.org/wiki/베이즈_정리) )

