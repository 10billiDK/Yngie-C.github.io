---
layout: post
title: 최대 우도 추정 & 최대 사후 확률 추정 (MLE & MAE)
category: Machine Learning
tag: Machine-Learning
---

본 포스트는 [문일철 교수님의 인공지능 및 기계학습 개론 I](https://www.edwith.org/machinelearning1_17/joinLectures/9738) 강의를 바탕으로 작성하였습니다.



# MLE

본 챕터에서는 **최대 우도 추정(Maximum Likelihood)** 에 대해서 알아보겠습니다. 최대 우도 추정을 알기위해 필요한 이항 분포(Binomial distribution)에 대해서 알아봅시다.



## Binomial Distribution(이항 분포)

아래와 같이 생긴 압정을 던져 가운데 압정처럼 뒤집어진 모양이 나올지, 아니면 양 옆에 위치한 압정처럼 엎어진 모양이 나올지를 예측하는 게임을 한다고 가정해봅시다. 이 때 편의상 엎어진 모양을 머리(Head, H)라고 하고 뒤집어진 모양을 꼬리(Tail, T)라고 표현합니다.

<img src="https://live.staticflickr.com/4106/4983417622_e29e2c3008_b.jpg" alt="thumbtack" style="zoom:50%;" />

<p align="center" style="font-size:80%">이미지 출처 : <a href="https://www.flickr.com/photos/22994840@N03/4983417622/sizes/l/">Flicker/thumbtack</a></p>

이 게임을 할 때 압정을 던지는 행위는 연속적(Continuous)이지 않습니다. 던지는 횟수가 1.123...번, 3.1415... 번과 같이 될 수 없고 1번, 2번, 3번 ... 과 같이 일종의 마디를 가지고 증가하기 때문입니다. 그렇기 때문에 이 게임에서 압정을 던지는 행위는 이산적(Discrete)이라고 할 수 있습니다. 그리고 이산적인 행위에서 특정 사건이 발생할 확률의 분포를 **이산 확률 분포(Discrete probability distribution)** 라고 합니다.

그리고 이 게임에서 발생할 수 있는 사건은 오직 머리(H)와 꼬리(T), 즉 사건의 개수는 '2' 입니다. 압정을 던지는 게임처럼 2가지 사건만을 가지는 것을 베르누이 시행(Bernoulli trial)이라고 부릅니다. 동전의 앞과 뒤, 특정 미션에 대한 성공 혹은 실패 등 다양한 상황에서 베르누이 시행을 찾아볼 수 있습니다.

이번에는 **독립 항등 분포(independent and identical distributed, i.i.d)** 에 대해서 알아봅시다. 단어의 듯에서도 알 수 있듯이 i.i.d는 독립적이며 동일한 확률 분포를 가지는 조건을 말합니다. 압정을 던지는 게임도 i.i.d 조건을 만족합니다. 압정을 한 번 던져 나온 사건의 결과는 이후 사건에 영향을 주지 않기 때문에 독립적(Independent)이라고 할 수 있습니다. 또한 압정을 던지는 행위의 확률 분포는 언제나 고유하기(Identical) 때문입니다.

위와 같은 것들이 가정되었다면 이 게임에서 특정 사건이 발생할 확률을 알 수 있습니다. 예를 들어, 압정을 5번 던져 (머리, 머리, 꼬리, 머리, 꼬리)가 나왔다고 합시다. 압정을 한 번 던져 머리가 나올 확률 $P(H) = \theta$ 라고 하면 (머리, 머리, 꼬리, 머리, 꼬리)의 순서대로 나타날 확률은 아래와 같이 나타낼 수 있습니다.


$$
P(HHTHT) = \theta \cdot \theta \cdot (1-\theta) \cdot \theta \cdot (1-\theta) = \theta^3 (1 - \theta)^2
$$


이를 일반화하면 $\theta$ 가 주어졌을 때 해당 데이터셋(Dataset) $D$ 가 발생할 확률인 $P(D \vert \theta)$ 로 나타낼 수 있습니다. 아래 식에서 $\alpha_H, \alpha_T$ 는 데이터셋 $D$ 에서 머리(H)와 꼬리(T)가 각각 발생한 횟수입니다.
$$
P(D|\theta) = \theta^{\alpha_H}(1 - \theta)^{\alpha_T}
$$
위 식은 $HHTHT$와 같이 정해진 순서대로 나왔을 때의 확률을 일반화하여 나타낸 것입니다. 그렇다면 순서에 상관없이 머리와 꼬리가 나타날 확률은 어떻게 구할 수 있을까요? 위에서 나타냈던 특정 한 사건(여기서는 머리)이 발생할 확률 $\theta$ 를 $p$로, 그 사건이 $\alpha_H$ 를 $k$ 로 바꿔줍시다. 그러면 임의의 순서대로 구성된 $n$ 개의 사건 세트에서 발생할 확률이 $p$ 인 특정 한 사건이 $k$ 번 나올 확률을 아래와 같은 함수 $f$ 로 나타낼 수 있습니다. 

$$
f(k;n,p) = P(K=k) = \left(\begin{array}{c}n\\k\end{array}\right) p^k (1-p)^{n-k}  \\
\because \left(\begin{array}{c}n\\k\end{array}\right) = \frac{n!}{k!(n-k)!}
$$



## Maximum Likelihood Estimation(최대 우도 추정)

특정 데이터셋으로부터 사건이 일어날 확률을 구하는 것은 중요합니다. 압정 게임이든 내일 비가 올 지 맑을지 예측하든 확률을 알아야 그에 맞춰 행동할 수 있기 때문입니다. 그렇다면 데이터셋 $D$ 로부터 압정 게임에서 머리(H)가 발생할 확률 $p$ 는 어떻게 추정할 수 있을까요? 우리가 알아볼 **최대 우도 추정(Maximum Likelihood Estimation)** 은 확률 $p$ 추정하기 위한 하나의 방법입니다. 최대 우도 추정은 말 그대로 현재 가지고 있는 데이터셋이 나올 확률을 최대화하는 우도(Likelihood) $\theta$ 를 구하는 것입니다. 수식으로는 아래와 같이 나타낼 수 있습니다.



$$
\hat{\theta} = \text{argmax}_{\theta} P(D \vert \theta)
$$



위 식에서 $\hat{\theta}$ 는 $P(D \vert \theta)$ 를 최대로 하는 $\theta$ 입니다. 위에서 알아본 식을 사용하여 이 식을  다음과 같이 나타낼 수 있습니다.


$$
\hat{\theta} = \text{argmax}_{\theta} P(D \vert \theta) = \text{argmax}_{\theta} \theta^{\alpha_H}(1 - \theta)^{\alpha_T} \\
\hat{\theta} = \text{argmax}_{\theta} \ln P(D \vert \theta) = \text{argmax}_{\theta} \{ \alpha_H \ln \theta + \alpha_T \ln (1 - \theta) \}
$$


위 첫 번째 식에서 구한 $\hat{\theta}$ 과 두 번째 식에서 구한 $\hat{\theta}$ 은 동일합니다. 로그 함수 $(\ln)$ 은 $[0,1]$ 에서 단조 증가 함수[^1] 이므로 $\text{argmax}$ 이후의 식에 함수를 취해주어도 변화하지 않습니다. 우리의 목표는 $\text{argmax}$ 이후에 위치한 식이 최댓값일 때의 $\theta$ 를 찾는 것입니다. 특정 함수의 도함수가 0이되는 지점이 있다면 그 점이 원래 함수의 최댓값 혹은 최솟값일 가능성이 있습니다. 그렇기 때문에 식을 미분한 후, 미분한 식의 값이 0이 되는 $\theta$ 를 구할 수 있습니다.


$$
\frac{d}{d\theta}(\alpha_H \ln \theta + \alpha_T \ln (1 - \theta)) = \frac{\alpha_H}{\theta} - \frac{\alpha_T}{1 - \theta} = 0 \\
\theta = \frac{\alpha_H}{\alpha_H + \alpha_T} \\
\therefore \quad \hat{\theta}_{MLE} = \frac{\alpha_H}{\alpha_H + \alpha_T}
$$


이제 최대 우도 추정을 통해 특정 데이터셋이 주어졌을 때 그 데이터셋이 일어날 확률을 최대로 하는 특정 사건이 일어날 확률 $\theta$ 를 구해낼 수 있게 되었습니다.



## Simple Error Bound(오차 범위)

위에서 알아본 바에 따르면 $\hat{\theta}$ 에 영향을 미치는 것은 $\alpha_H$ 과 $\alpha_T$ 의 비율입니다. 전체 횟수인 $n$ 이 커지더라도 이 비율만 지켜진다면 $\hat{\theta}$ 은 동일하게 됩니다.

동일한 비율을 가진 두 개의 데이터셋을 예로 들어봅시다. 한 데이터셋은 5번 던져 머리가 3번, 꼬리가 2번 나왔다고 합니다. 나머지 하나의 데이터셋은 50번 던져 머리가 30번, 꼬리가 20번 나온 경우입니다. 두 데이터셋 모두 최대 우도 추정을 통해 사건의 확률을 구하면 $\hat{\theta} = 0.6 = 3/(3+2) = 30/(30+20)$ 입니다. 그렇다면 두 데이터셋은 아무런 차이가 없는 것일까요? 데이터셋이 가지는 비율만 일정하다면 더 큰 데이터셋이 주는 이점은 없을까요?

질문에 대한 답은 "아니다"입니다. 일단 우리가 지금까지 알아본 $\hat{\theta}$ 은 그저 추정값일뿐 실제 확률이 아닙니다. 추정값은 언제나 실제값과 오차가 있기 마련입니다. 오차는 둘 사이의 차이이므로 절댓값을 활용하여 $\vert \hat{\theta} - \theta^\* \vert$ 로 나타낼 수 있습니다. 수학자들은 이 오차에 수학적 기술을 적용하여 오차의 범위(Error bound)를 구하는 식을 만들어 놓았습니다. 오차의 범위를 구하는 식은 아래와 같습니다.


$$
P(\vert \hat{\theta} - \theta^* \vert \geq \epsilon ) \leq 2e^{-2N \epsilon^2} \\
\because N = a_H + a_T
$$


위 식을 보면 오차가 임의의 작은 값 $\epsilon$ 보다 커질 확률은 $2e^{-2N \epsilon^2}$ 로 나타납니다. 즉, $\epsilon$ 이 동일한 조건에서는 실행횟수 $N$ 이 증가할수록 오차의 범위가 줄어들게 된다는 의미입니다. 이러한 학습 방식을 팩 학습(Probably Approximate Correct learning, PAC learning)이라고 합니다. PAC learning의 목적은 높은 확률(Probably)로 낮은 오차 범위(Approximately Correct)를 갖도록 하는 것입니다. 즉 이를 달성하기 위해서는 데이터셋이 많아야 하고, 향후 머신러닝에서 커다란 데이터셋이 중요한 이유도 이 때문입니다.



# MAP

## Incorporating Prior Knowledge

MLE 말고도 확률을 바라보는 다른 관점이 있다. MLE는 우리가 알고 있는 사전 지식을 확률에 반영하지 않는다. 새로운 관점은 확률 계산에 사전 지식 $P(\theta )$ 을 넣는다. 그렇게 계산되어 나오는 확률은 MLE에서 계산했던 $P(D \vert \theta)$ 가 아닌 $P(\theta \vert D)$ 이다. MLE에서는 주어진 $\theta$ 에 대해서 $D$ 가 발생할 확률을 구했다면, **MAP(Maximum a Posterior Estimation)** 에서는 주어진 $D$ 에 대해서 $\theta$ 인 확률, 즉 사후 확률(Posterior)을 구한다.


$$
P(\theta \vert D) = \frac{P(D \vert \theta) P(\theta)}{P(D)} \\
\text{Posterior} = \frac{\text{Likelihood}\times \text{Prior Knowledge}}{\text{Normalizing Constant}}
$$



## Bayes Viewpoint

위 식에서 $P(D)$ 는 상수이므로 $P(\theta \vert D) \propto P(D \vert \theta) P(\theta)$ 로 나타낼 수 있다. 여기서 $P(D \vert \theta) = \theta^{a_H}(1 - \theta)^{a_T}$ 로 나타낼 수 있다. 사전 지식인 $P(\theta)$ 는 Beta distribution(베타 분포)를 사용해서 구할 수 있다.


$$
P(\theta) = \frac{\theta^{\alpha-1}(1 - \theta)^{\beta-1}}{B(\alpha, \beta)} \\
B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)} ,\quad \Gamma(\alpha) = (\alpha-1)!
$$



## Maximum a Posteriori Estimation(최대 사후 확률 추정)

위에서 나온 식을 같은 밑끼리 정리하면 아래와 같이 쓸 수 있다. 


$$
P(\theta \vert D) \propto P(D \vert \theta) P(\theta) =  \theta^{a_H}(1 - \theta)^{a_T} \cdot \theta^{\alpha-1}(1 - \theta)^{\beta-1} = \theta^{a_H + \alpha -1}(1 - \theta)^{a_T +\beta-1}
$$


MLE에서 $P(D \vert \theta) = theta^{a_H}(1 - \theta)^{a_T}$ 를 최대화하는 $\hat{\theta} = \frac{a_H}{a_H + a_T}$ 임을 이용하여  $P(\theta \vert D)$ 를 최대화하는 $\hat{\theta}$ 의 값도 나타낼 수 있다.


$$
P(\theta \vert D) \propto \theta^{a_H + \alpha -1}(1 - \theta)^{a_T +\beta-1} \\
\hat{\theta}_{MAP} = \frac{a_H + \alpha -1}{a_H + \alpha + a_T +\beta - 2}
$$



MLE와 MAP 방식으로 구해진 $\hat{\theta}$ 은 $\alpha=\beta=1$ 인 경우를 제외하고는 서로 같지 않다. 하지만 $N$ 이 커질수록(시도가 늘어날수록) $a_H , a_T$ 가 커지게 되어 점점 비슷해지게 된다. 



[^1]: 어떤 수열이나 함수가 있을 때, 해당 수열이나 함수가 정의된 구간에서 감소하지 않는 경우를 단조증가, 증가하지 않는 경우를 단조감소 함수라고 한다. 위 그림에서 오른쪽 그래프의 경우 중간에 감소하는 구간이 존재하므로 해당 그래프는 단조증가 함수가 아니나, 왼쪽의 그래프의 경우 감소하는 구간이 존재하지 않으므로 단조증가 함수라고 할 수 있다. 결국 감소하는 구간이 없는 경우란 값이 일정하거나 증가하는 구간밖에 없는 경우가 된다. 이 단조증가에서 모든 구간에서 항상 수치가 증가하는 경우를 ‘강한 단조증가’라고 하기도 한다. 출처 : 과학포털 사이언스올