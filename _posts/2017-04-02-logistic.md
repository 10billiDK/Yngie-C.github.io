---
title: Logistic Regression
category: Machine Learining
tag: Logistic Regression
html header: <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"></script>
---

이번 포스팅에선 분류 문제에 대해 회귀식의 형태로 예측하는 모델인 **로지스틱 회귀(Logistic Regression)**에 대해 살펴보려고 합니다. 이번 글은 고려대 강필성 교수님과 역시 같은 대학의 김성범 교수님 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.



## 모델의 문제의식

**다중선형회귀(Multiple Linear Regression)**는 수치형 설명변수 X와 연속형 숫자로 이뤄진 종속변수 Y간의 관계를 선형으로 가정하고 이를 가장 잘 표현할 수 있는 회귀계수를 데이터로 추정하는 모델입니다. 이 회귀계수들은 모델의 예측값과 실제값의 차이, 즉 **오차제곱합(error sum of squares)**을 최소로 하는 값들입니다. 이러한 최적 계수들은 회귀계수에 대해 미분한 식을 0으로 놓고 풀면 명시적인 해를 구할 수 있습니다. 어쨌든 설명변수가 p개인 다중선형회귀의 일반 식은 아래와 같이 쓸 수 있습니다.

$$y={ \beta  }_{ 0 }+{ \beta  }_{ 1 }{ x }_{ 1 }+{ \beta  }_{ 2 }{ x }_{ 2 }+...+{ \beta  }_{ p }{ x }_{ p }+\varepsilon $$

한번 예를 들어보겠습니다. 33명의 성인 여성에 대한 나이와 혈압 데이터가 좌측 하단 표와 같이 주어졌다고 칩시다. 그러면 우리는 오차제곱합을 최소로 하는 회귀계수를 구할 수 있고 이를 그래프로 그리면 우측 하단 그림과 같습니다. 나이라는 설명변수에 대응하는 계수는 1.222로 나타났는데요, 이를 통해 우리는 나이를 한살 더 먹으면 혈압이 1.222mm/Hg만큼 증가한다는 걸 알 수 있게 됩니다.

<a href="http://imgur.com/muiAC6k"><img src="http://i.imgur.com/muiAC6k.png" width="700px" title="source: imgur.com" /></a>

그러면 혈압이라는 연속형 숫자 대신 범주형 변수를 이용해 위와 같은 회귀모델을 구축한다면 어떤 일이 발생할까요? 좌측 하단과 같이 나이와 암 발생여부(1이면 발병, 0이면 정상) 데이터가 주어졌다고 칩시다. 이를 위와 동일한 방식으로 회귀모델을 구축하고 그래프로 그리면 우측 하단과 같이 우스꽝스러운 그림이 될 겁니다.

<a href="http://imgur.com/Co19p9c"><img src="http://i.imgur.com/Co19p9c.png" width="700px" title="source: imgur.com" /></a>

위와 같은 문제가 발생하는 근본적인 이유는 종속변수 Y의 성질 때문입니다. 혈압의 경우 숫자 그 자체로 의미를 지니는 변수이지만, 암 발생여부는 그렇지 않습니다. 발병(1)과 정상(0) 사이에 중간이 없을 뿐더러 심지어 정상을 1, 발병을 0으로 바꾸어도 큰 상관이 없습니다. 암 발생여부와 같이 그 속성이 **범주형(categorical)**일 때는 연속형 숫자에 적용되는 다중선형회귀 모델을 그대로 적용할 수 없다는 뜻이기도 합니다. 이러한 문제 때문에 범주형 변수에 대해 로지스틱 회귀 모델이 제안됐습니다.



## 로지스틱 함수와 Odds

우선 로지스틱 회귀 모델에 대해 본격적으로 살펴보기 전 중간 과정으로 **로지스틱 함수(Logistic Function)**와 **승산(Odds)**에 대해 알아보겠습니다. 이 개념이 로지스틱 회귀의 뼈대가 되는 아이디어이기 때문입니다.

실제 많은 자연, 사회현상에서는 특정 변수에 대한 확률값이 선형이 아닌 S-커브 형태를 따르는 경우가 많다고 합니다. 이러한 S-커브를 함수로 표현해낸 것이 바로 로지스틱 함수입니다. 분야에 따라 **시그모이드 함수**로도 불리기도 하는데요, x값으로 어떤 값이든 입력받을 수가 있지만 출력 결과는 항상 0에서 1사이 값입니다. 즉 **확률밀도함수(probability density function)** 요건을 충족시키는 함수라는 이야기입니다. 그 식과 그래프 모양은 아래와 같습니다.

$$y=\frac { 1 }{ 1+{ e }^{ -x } } $$

<a href="http://imgur.com/E0eI8OU"><img src="http://i.imgur.com/E0eI8OU.png" width="500px" title="source: imgur.com" /></a>

승산(Odds)이란 임의의 사건 A가 발생하지 않을 확률 대비 일어날 확률의 비율을 뜻하는 개념입니다. 아래와 같은 식으로 쓸 수가 있습니다.

$$odds=\frac { P(A) }{ P({ A }^{ c }) } =\frac { P(A) }{ 1-P(A) } $$

만약 P(A)가 1이라면 승산은 무한대로 치솟을 겁니다. 반대로 P(A)가 0이라면 0이 될 겁니다. 바꿔 말하면 승산이 커질수록 사건 A가 발생할 확률이 커진다고 이해해도 될 겁니다. 



## 이항 로지스틱 회귀

이제 로지스틱 함수와 승산 개념을 하나로 묶어서 이해해볼까요? 이렇게 생각해봅시다. 범주가 두 개인 분류 문제를 풀어야 한다고 가정을 해보는 거죠. 앞선 챕터에서 말씀드렸듯 종속변수 Y가 연속형 숫자가 아닌 범주(1 또는 0)일 때는 선형 회귀 모델을 적용할 수가 없습니다. 그럼 문제를 바꿔서 풀어봅시다. 회귀식의 장점은 그대로 유지하되 종속변수 Y를 범주가 아니라 **해당 범주의 승산(Odds)**으로 두자는 말입니다.

하지만 승산의 범위는 이전 챕터에서 말씀드렸듯 0에서 무한대의 범위를 갖습니다. 하지만 회귀식은 음의 무한대에서 양의 무한대 범위를 가지기 때문에 범위에 대한 제약이 존재합니다. 여기서 승산에 로그를 취하면 어떻게 될까요? 이렇게 되면 로그 승산 또한 음의 무한대에서 양의 무한대로 그 범위가 변환되게 됩니다. 이로써 회귀식의 범위와 일치하게 되는 셈이지요. 그렇다면 로그 승산을 활용해 이진 분류를 위한 회귀분석 식을 쓰면 아래와 같은 형태가 됩니다.

$$P(Y=1|X=x)=\pi (X=x)\\ \log { (Odds) } =\log { (\frac { \pi (x) }{ 1-\pi (x) } ) } ={ \beta  }_{ 0 }+{ \beta  }_{ 1 }{ x }_{ 1 }+{ \beta  }_{ 2 }{ x }_{ 2 }+...+{ \beta  }_{ p }{ x }_{ p }$$

위 식에서 Odds는 관측치 x가 범주 1에 속할 확률 대비 0에 속할 확률 간의 비율을 뜻합니다. 그럼 회귀계수들의 의미를 곱씹어볼까요? 변수 x1에 대응하는 1번 회귀계수가 학습 결과 2.5로 정해졌다고 칩시다. 그렇다면 x1이 1단위 증가하면 범주 1에 해당하는 로그 승산이 2.5만큼 증가한다고 해석할 수 있게 됩니다. 이는 일반적인 선형 회귀와 유사한 모습이죠. 어쨌든 위 식 양변에 exp의 지수를 취해주면 로그의 성질에 의해 아래와 같은 식으로 변환됩니다. 이를 파이(=범주 1에 속할 확률=성공확률)를 기준으로 정리하면 최종 식이 나옵니다.
$$
\begin{align*}
\frac { \pi (x) }{ 1-\pi (x) } &={ e }^{ { \beta  }_{ 0 }+{ \beta  }_{ 1 }{ x }_{ 1 }+{ \beta  }_{ 2 }{ x }_{ 2 }+...+{ \beta  }_{ p }{ x }_{ p } }\\ \pi (x)&=\frac { 1 }{ 1+{ e }^{ -({ \beta  }_{ 0 }+{ \beta  }_{ 1 }{ x }_{ 1 }+{ \beta  }_{ 2 }{ x }_{ 2 }+...+{ \beta  }_{ p }{ x }_{ p }) } } 
\end{align*}
$$

위 식 어디서 많이 본 형태 아닙니까? 네 맞습니다. 바로 직전 챕터에서 설명드린 로지스틱 함수입니다. 이 식에 범주 정보를 모르는 관측치 x를 넣으면 범주 1에 속할 확률을 반환해 줍니다. 그 확률이 0.5보다 크면 범주 1로, 이보다 작으면 범주 0으로 분류하면 됩니다.



## 다항 로지스틱 회귀

그렇다면 범주가 세 개 이상인 다항 로지스틱 회귀는 어떻게 이해하면 될까요? 우선 범주가 3개뿐이라고 가정해 보겠습니다. 그렇다면 지금까지의 방식 그대로 로그 승산을 좌변, 회귀식을 우변에 둔 아래 식을 쓸 수가 있습니다.

$$\log { \frac { P(Y=1|X=x) }{ P(Y=3|X=x) }  } ={ \beta  }_{ 10 }+{ \beta  }_{ 1 }{ x }\\ \log { \frac { P(Y=2|X=x) }{ P(Y=3|X=x) }  } ={ \beta  }_{ 20 }+{ \beta  }_{ 2 }{ x }$$

위 두 개 수식 양변에 exp 지수를 취해주면 좌변의 분모가 같아지는데 모든 식을 곱해 이를 정리해주면 아래와 같이 식을 다시 쓸 수 있습니다. 저 같은 경우 승산을 취할 때 분모로 범주 3을 선택했는데, 사실 1을 취하든 2을 선택하든 관계는 없습니다. 어쨌든 관측치 X가 주어졌을 때 해당 관측치가 범주 3에 속할 확률은 아래와 같습니다.

$$P(Y=3|X=x)=\frac { { e }^{ { \beta  }_{ 30 }+{ \beta  }_{ 3 }x } }{ 1+{ e }^{ { \beta  }_{ 10 }+{ \beta  }_{ 20 }+{ \beta  }_{ 1 }x+{ \beta  }_{ 2 }x } } $$

마찬가지로 범주 1에 속할 확률, 2에 속할 확률도 얼마든지 구할 수 있습니다. 각 확률을 모두 구한 뒤 가장 높은 확률값을 내는 범주로 분류를 하는 방식입니다. 관측치 x가 주어졌을 때 k번째 클래스로 분류될 확률은 아래 식과 같습니다.

$$P(Y=k|X=x)=\frac { { e }^{ { \beta  }_{ k0 }+{ \beta  }_{ k }^{ T }x } }{ 1+\sum _{ i=1 }^{ K-1 }{ { e }^{ { \beta  }_{ i0 }+{ \beta  }_{ i }^{ T }x } }  } ,\quad k=1,2,...,K-1$$



## 로지스틱 회귀의 파라메터 추정

로지스틱 회귀의 종속변수는 승산 확률이기 때문에 **최우추정법(Maximum Likelihood Estimation)**으로 구합니다. 다만 우도함수는 추정 대상 파라메터인 회귀계수 β에 대해 비선형이기 때문에 선형회귀와 같이 명시적인 해가 존재하지 않습니다. 따라서 **뉴턴-랩슨법(Newton-Raphson Method)** 같은 점진적이고 반복적인 방식을 통해 해를 찾게 됩니다. 예컨대 아래와 같습니다. (출처 : [영문 위키피디아](https://en.wikipedia.org/wiki/Newton%27s_method))

<a href="http://imgur.com/uCLGlkK"><img src="http://i.imgur.com/uCLGlkK.gif" width="500px" title="source: imgur.com" /></a>

